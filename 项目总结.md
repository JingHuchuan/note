先出一个总模型，然后去细化补充。

### 一、总述问题

#### 1. 简单介绍一下你的项目？

这个项目主要的目的是对**浏览器的链接请求进行解析处理，处理完之后给浏览器客户端返回一个响应，如文字图片视频等**。服务器后端的处理方式**使用socket通信，利用epoll多路IO复用**，可以同时处理多个请求，请求的解析使**用预先准备好的线程池**，使用模拟proactor模式，**主线程负责监听**，监听到有事件之后，从socket中循环读取数据，然后将读取到的数据封装成一个请求对象插入请求队列。睡眠在请求队列上的**工作线程被唤醒进行处理**。处理的方式用**状态机**。

详细：对请求文件的处理：客户端发出链接，到达服务器，服务器这端先用read_once（）函数一次性把所有请求读到缓冲区。然后process_read函数分别调用用三个函数对缓冲区的内容进行解析。主状态机主要用于解析客户端请求，从状态机用于解析一行内容并把每一行加\0\0格式化，方便主状态机解析，主状态机调用解析请求行，请求头，请求内容三部分函数进行解析。解析结束后利用do_request（）函数生成响应报文，该函数会根据不同的网址url产生不同响应体。最后通过write函数里套接字的传输方式把响应体传给客户端。

日志分为**同步日志和异步日志**，异步日志利用阻塞队列，先将日志放入阻塞队列中，然后利用条件变量将日志添加到对应文件中。采用**单例模式**实现。

日志系统初始化函数中主要要做的事：如果文件名没带路径，直接放到log_full_name。如果带路径，把文件名取出来放到log_name，把路径取出来放到dir_name，然后把时间+log_name放到log_full_name。

在write_log（）函数中，这里面有两部分，一部分是对新的文件名，时间，日志名进行再次处理，一部分是时间+新加入的日志参数放入缓冲区。异步加入阻塞队列，同步直接写入日志文件。阻塞队列是用数组模拟的生产者消费者模式。根据初始化函数传入的最后一个参数阻塞队列最大容纳值判断是同步还是异步，异步则其大于等于1。

用**单例模式创建了数据库连接池**。数据库链接池中，提前创建一定量的数据链接，并把他们保存在链表中。

用定时器处理非活跃连接，定时器基于**时间轮**实现。



#### 2.为什么要做这样一个项目？

在学习cpp语言的时候，需要做一个项目巩固一下所学的知识点，网上有推荐这个项目，然后就自己尝试做了一下。这个项目综合性比较强，从中既能学习**Linux环境下的一些系统调用**，也能**熟悉网络编程**。

通过学习做这个项目我学习到了：

**socket通信的流程，HTTP报文解析，多线程，包括线程池，数据库连接池，IO，锁，已经单例模式的设计思想**。



#### 3. 你的项目有什么技术难点？

待完善。



#### 4. 为什么所有人都是这个服务器项目？

自己能接触到的适合现阶段的最好的项目就是WebServer，也不知道其他人都做这个。



#### 5. 后面需要添加的功能？

添加文件上传与下载功能，实现与服务器真正的交互。



#### 6. **这个web服务器是你自己申请的域名么？域名号是多少？**

没有申请，因为服务器是放在同一网段的虚拟机里，然后在本地的浏览器输入本地环回地址127.0.0.1加相应的端口号即可访问服务器。

也试过使用docker将这个项目部署到阿里云，并通过端口映射将公网的IP的端口映射到云服务虚拟机内网的端口，然后在该虚拟机上的某个端口运行该服务器程序。通过端口映射，就可以使用公网ip加相应端口号就可以访问服务器了。



### 二、线程池与多线程相关问题

#### 1. 什么是线程池，线程池有什么好处

所谓线程池，通俗来讲，就是一个管理线程的池子。它可以容纳多个线程，其中的线程可以反复利用，省去了频繁创建线程对象的操作。
**好处：**

- 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗；

- 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行；

- 高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

  

**问：类似的技术还有哪些？**

数据库连接池，内存池，对象池。



**问：你这个项目里面是具体怎么实现和使用线程池的？**

在这个项目中，我首先实现了一个简单的线程池模板类，主要的参数包括**线程池中的线程数**，**请求队列中允许的最大请求数** ，**请求队列**，**是否有任务需要处理**的信号量，**是否结束线程**标志这几个参数，在最开始的时候创建指定数量的线程，并将其设置为**脱离**状态，这样的做的好处是在所有任务执行结束之后，线程会自动销毁，不用专门去销毁。我们定义了一个http_conn类，主要设计思路就是利用**有限状态机**对http请求报文进行解析。我们使用了http_conn实例化线程池模板类，再主线程中使用epoll监听套接字，接收socket连接，若当前监听的socket发生了读写事件，我们就将该请求的处理（即http报文解析）到线程池的请求队列中，此时线程池中统计**是否有任务处理的信号量**加1，表明有任务需要处理，睡眠在请求队列上的**工作线程被唤醒进行处理**。这也是**Proactor**模式的工作流程。



**问：你可以简单写一下你实现的线程池吗？**

可以，下面就是一个我在项目中实现的线程池：

```cpp
#ifndef THREADPOOL_H
#define THREADPOOL_H

#include <list>
#include <cstdio>
#include <exception>
#include <pthread.h>

// 线程池类，将它定义为模板类是为了代码复用。模板参数T是任务类
template<typename T>
class threadpool {
public:
        // 参数thread_number是线程池中线程的数量，max_requests是请求队列中最多允许的、等待处理的请求的数量
    threadpool(int thread_number = 8, int max_requests = 10000);      //构造函数定义，此时可以有初始值
    ~threadpool();

    // 往请求队列中添加任务
    bool append(T* request);
 
private:
    // 工作线程运行的函数，它不断从工作队列中取出任务并执行之
    // 线程的工作函数，在c++中必须是static，这是规定
    static void* worker(void* arg);
    void run();
    
private:
    // 线程池参数
    int m_thread_number;        //线程池中的线程数
    int m_max_requests;         //请求队列中允许的最大请求数
    pthread_t* m_threads;       //描述线程池的数组，其大小为m_thread_number
    std::list<T*> m_workqueue;  //请求队列
    pthread_mutex_t mutex;      //保护请求队列的互斥锁
    sem m_queuestat;            //是否有任务需要处理
    bool m_stop;                //是否结束线程

 
template<typename T>
threadpool<T>::threadpool(int thread_number, int max_requests) : 
    m_thread_number(thread_number), m_max_requests(max_requests), 
    m_stop(false), m_threads(NULL) {
    if ((thread_number <= 0) || (max_requests <= 0)) {
        throw  std::exception();
    }

    m_threads = new pthread_t[m_thread_number];
    if (!m_threads) {
        throw std::exception();
    }

    // 创建thread_number个线程，并将他们都设置为脱离线程，就会自己销毁，不用自己销毁
    for (int i = 0; i < thread_number; ++i) {
        printf("create the %dth thread\n", i);
        if (pthread_create(m_threads + i, NULL, worker, this) != 0) {
            delete[] m_threads;
            throw std::exception();
        }

        // pthread_detach成功时返回0，失败时返回非0
        if (pthread_detach(m_threads[i])) {
            delete[] m_threads;
            throw std::exception();
        }
    }
}
    
template<typename T>
threadpool<T>::~threadpool() {
    delete[] m_threads;
    m_stop = true;
}

// 向请求队列中添加任务
template<typename T>
bool threadpool<T>::append(T* request, int state) {
    // 操作工作队列时一定要加锁，因为它被所有线程共享
    pthread_mutex_lock(&mutex);

    // 根据硬件，预先设置请求队列的最大值
    if (m_workqueue.size() >= m_max_requests) {
        pthread_mutex_unlock(&mutex);
        return false;
    }

    // 添加任务
    m_workqueue.push_back(request);
    pthread_mutex_unlock(&mutex);
    m_queuestat.post();                 // 增加一个任务就需要相应增加一个信号量，用于通知等待的线程有新的任务可用
    return true;
}
    
template<typename T>
void* threadpool<T>::worker(void* arg) {
    // 调用pthread_create的时候，将this作为参数传给worker，然后通过指针的强转，得到对象，再调用run函数，即可访问非静态成员变量 
    // worker函数是static的，不能直接访问非statice的成员，worker的参数arg就是this，可以通过强制转换得到
    threadpool* pool = (threadpool*) arg;
    pool->run();
    return pool;
}
    
template<typename T>
void threadpool<T>::run() {
    while (!m_stop) {
        // 使用m_queuestat.wait()判断信号量是否有值，如果有值的话信号量就减1，如果没有值就阻塞在这里
        m_queuestat.wait();
        pthread_mutex_lock(&mutex);
        if (m_workqueue.empty()) {
            // 如果请求队列为空的话，不进行处理
            pthread_mutex_unlock(&mutex);
            continue;
        }

        T* request = m_workqueue.front();     // 获取第一个任务
        m_workqueue.pop_front();              // 在工作队列中删除
        pthread_mutex_unlock(&mutex);

        if (!request) {
            continue;                         // 如果没有请求到，就continue
        }

        request->process();                   // 任务类的process
    }
}

#endif
```

上述的线程池代码中有几个需要注意的点：

pthread_create函数开启一个线程，其回调函数只能是静态函数，但是静态函数是不能调用类中的非静态成员的，所以需要将pthread_create函数的最后 一个参数设置为this，表示将this作为参数传给回调函数，这样一来，在回调函数中就可以使用指针强转得到类指针，然后就可以调用非静态成员和函数了。



#### 2. 线程同步机制

**什么是线程同步和线程互斥**？

**线程同步**：线程同步只的是多个线程之间的协调同步，按照与预定的先后次序进行运行，这种先后次序取决于要完成的特定任务，最基本的场景就是：A线程要完成的任务依赖于B线程的任务。

**线程互斥**：线程互斥是对于线程共享的线程资源，在各个线程访问时具有排他性。当有若干个线程要访问同一资源时，任何时候只能由一个线程访问，直到占有资源者放弃使用该资源。线程同步可以看作一种特殊的线程同步。

**线程同步的方式**：

线程同步的方式主要有互斥锁，条件变量，信号量，读写锁，自旋锁等。

1. **互斥锁**

   互斥锁本质就是一个特殊的全局变量，拥有lock和unlock两种状态，unlock的互斥锁可以由某个线程获得，当互斥锁由某个线程持有后，这个互斥锁会锁上变成lock状态，此后只有该线程有权力打开该锁，其他想要获得该互斥锁的线程都会阻塞，直到互斥锁被解锁。互斥锁又分为一下几种：

   - **普通锁（PTHREAD_MUTEX_NORMAL）**：互斥锁默认类型。当一个线程对一个普通锁加锁以后，其余请求该锁的线程将形成一个 等待队列，并在该锁解锁后按照优先级获得它，这种锁类型保证了资源分配的公平性。一个 线程如果对一个已经加锁的普通锁再次加锁，将引发死锁；对一个已经被其他线程加锁的普 通锁解锁，或者对一个已经解锁的普通锁再次解锁，将导致不可预期的后果。
   - **检错锁（PTHREAD_MUTEX_ERRORCHECK）**：一个线程如果对一个已经加锁的检错锁再次加锁，则加锁操作返回EDEADLK；对一个已 经被其他线程加锁的检错锁解锁或者对一个已经解锁的检错锁再次解锁，则解锁操作返回 EPERM。
   - **嵌套锁**（PTHREAD_MUTEX_RECURSIVE）：该锁允许一个线程在释放锁之前多次对它加锁而不发生死锁；其他线程要获得这个锁，则当前锁的拥有者必须执行多次解锁操作；对一个已经被其他线程加锁的嵌套锁解锁，或者对一个已经解锁的嵌套锁再次解锁，则解锁操作返回EPERM。
   - **默认锁**（PTHREAD_MUTEX_ DEFAULT）：一个线程如果对一个已经加锁的默认锁再次加锁，或者虽一个已经被其他线程加锁的默 认锁解锁，或者对一个解锁的默认锁解锁，将导致不可预期的后果；这种锁实现的时候可能 被映射成上述三种锁之一。

   使用下面的函数设置互斥锁：

   ```cpp
   
   // 静态方式创建互斥锁
   pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; 
   
   // 动态方式创建互斥锁，其中参数mutexattr用于指定互斥锁的类型，具体类型见上面四种，如果为NULL，就是普通锁。
   int pthread_mutex_init (pthread_mutex_t* mutex,const pthread_mutexattr_t* mutexattr);
   
   int pthread_mutex_lock(pthread_mutex_t *mutex); // 加锁，阻塞
   int pthread_mutex_trylock(pthread_mutex_t *mutex); // 尝试加锁，非阻塞
   int pthread_mutex_unlock(pthread_mutex_t *mutex); // 解锁
   
   // 例子
   #include<stdio.h>
   #include<pthread.h>
   
   int ticket_num=10000000;
   
   pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER;
   
   void *sell_ticket(void *arg) {
       while(ticket_num>0) {
   	pthread_mutex_lock(&mutex);
   	if(ticket_num>0) {
   	    ticket_num--;
   	}
   	pthread_mutex_unlock(&mutex);
       }
   }
   
   int main() {
       pthread_t t1,t2,t3;
       pthread_create(&t1, NULL, &sell_ticket, NULL);
       pthread_create(&t2, NULL, &sell_ticket, NULL);
       pthread_create(&t3, NULL, &sell_ticket, NULL);
       pthread_join(t1, NULL);
       pthread_join(t2, NULL);
       pthread_join(t3, NULL);
       printf("ticket_num=%d\n", ticket_num);
       return 0;
   }
   ```

2. **自旋锁**

   **自旋锁是专为防止多处理器并发而引入的一种锁**，自旋锁顾名思义就是一个死循环，不停的轮询，当一个线程未获得自旋锁时，不会像互斥锁一样进入阻塞休眠状态，而是**不停的轮询获取锁**，**如果自旋锁能够很快被释放，那么性能就会很高**，如果自旋锁长时间不能够被释放，甚至里面还有大量的IO阻塞，就会导致其他获取锁的线程一直空轮询，导致CPU使用率达到100%，特别CPU时间。

   **自旋锁的初衷就是**：在短期间内进行轻量级的锁定。一个被争用的自旋锁使得请求它的线程在等待锁重新可用的期间进行自旋（特别浪费处理器时间），所以自旋锁不应该被持有 时间过长。如果需要长时间锁定的话, 最好使用信号量。

   ```cpp
   int pthread_spin_init(pthread_spinlock_t *lock, int pshared);
   // pshared可取以下属性:
   // PTHREAD_PROCESS_PRIVATE 
   // PTHREAD_PROCESS_SHARED 
   
   int pthread_spin_destroy(pthread_spinlock_t *lock); 
   int pthread_spin_lock(pthread_spinlock_t *lock);
   
   int pthread_spin_trylock(pthread_spinlock_t *lock); 
   int pthread_spin_unlock(pthread_spinlock_t *lock);
   
   // 例子
   #include<stdio.h>
   #include<pthread.h>
   
   int ticket_num=10000000;
   
   pthread_spinlock_t spinlock;
   
   void *sell_ticket(void *arg) {
       while(ticket_num>0) {
   	pthread_spin_lock(&spinlock);
   	if(ticket_num>0) {
   	    ticket_num--;
   	}
   	pthread_spin_unlock(&spinlock);
       }
   }
   
   int main() {
       pthread_spin_init(&spinlock, 0);
       pthread_t t1,t2,t3;
       pthread_create(&t1, NULL, &sell_ticket, NULL);
       pthread_create(&t2, NULL, &sell_ticket, NULL);
       pthread_create(&t3, NULL, &sell_ticket, NULL);
       pthread_join(t1, NULL);
       pthread_join(t2, NULL);
       pthread_join(t3, NULL);
       printf("ticket_num=%d\n", ticket_num);
       return 0;
   }
   ```

3. **条件变量**

   信号量是一个计数器，用于控制访问有限共享资源的线程数。具体而言，信号量设置为几，就允许同时几个线程访问公共资源。

   具体的实现方法如下：

   ```cpp
   // 创建信号量
   // pshared：一般取0，表示调用进程的信号量。非0表示该信号量可以共享内存的方式，为多个进程所共享(Linux暂不支持)。
   // value：信号量的初始值，可以并发访问的线程数。
   int sem_init (sem_t* sem, int pshared, unsigned int value);
   
   int sem_wait (sem_t* sem); // 信号量减1，信号量为0时就会阻塞
   
   int sem_trywait (sem_t* sem); // 信号量减1，信号量为0时返回-1，不阻塞
   
   int sem_timedwait (sem_t* sem, const struct timespec* abs_timeout); // 信号量减1，信号量为0时阻塞，直到abs_timeout超时返回-1
   
   int sem_post (sem_t* sem); // 信号量加1
   
   #include<stdio.h>
   #include<pthread.h>
   #include <semaphore.h>
   
   int ticket_num=10000000;
   
   sem_t sem;
   
   void *sell_ticket(void *arg) {
       while(ticket_num>0) {
   	sem_wait(&sem);
   	if(ticket_num>0) {
   	    ticket_num--;
   	}
   	sem_post(&sem);
       }
   }
   
   int main() {
       sem_init(&sem, 0, 1); // value=1表示最多1个线程同时访问共享资源，与互斥量等价
       pthread_t t1,t2,t3;
       pthread_create(&t1, NULL, &sell_ticket, NULL);
       pthread_create(&t2, NULL, &sell_ticket, NULL);
       pthread_create(&t3, NULL, &sell_ticket, NULL);
       pthread_join(t1, NULL);
       pthread_join(t2, NULL);
       pthread_join(t3, NULL);
       printf("ticket_num=%d\n", ticket_num);
       return 0;
   }
   ```

   在上面的例子中，我们开始设置信号量的值为1，表示同时只能有1个线程访问公共资源。在临界区之前，我们使用了sem_wait(&sem);将信号量减1，此时就为0，这里就会阻塞住，如果其他线程访问的话，就会阻塞在这里，所以二进制信号量和互斥锁的功能是一样的。

   **互斥锁和信号量的区别**：互斥量任何时候都只允许一个线程访问共享资源，而信号量则允许最多value个线程同时访问共享资源，当value为1时，与互斥量等价。

4. **条件变量**

   **最复杂的一个**

   条件变量可以让调用线程在满足特定条件的情况下运行，不满足条件时**阻塞等待被唤醒**，必须与互斥锁搭配使用。

   **条件变量常用于生产者与消费者模型。**

   生产者消费者模型
   生产者：产生数据的线程。
   消费者：使用数据的线程。

   ![img](https://pic2.zhimg.com/80/v2-2eaa9482f08f4de702fcb456bd83bbf1_720w.webp)

   通过缓冲区隔离生产者和消费者，与二者直连相比，避免相互等待，提高运行效率。
   生产快于消费，缓冲区满，撑死。
   消费快于生产，缓冲区空，饿死。

   生产者与消费者模型的优势：

   1. 降低生成者与消费者之间的耦合度；
   2. 支持忙闲不均，生成者生成速度快，不一样要等到有空闲的消费者，只要将数据放到缓冲区即可，等待消费者去处理；
   3. 支持并发，多个生产者线程和多个消费者同时刻执行自己的任务。

   以下是一些方法：

   ```cpp
   pthread_cond_t cond=PTHREAD_COND_INITIALIZER; // 创建条件变量，一个互斥锁可以对应多个条件变量
   
   int pthread_cond_wait (pthread_cond_t* cond,pthread_mutex_t* mutex); // 阻塞等待条件满足，同时释放互斥锁mutex
   
   int pthread_cond_timedwait (pthread_cond_t* cond,
       pthread_mutex_t* mutex,
       const struct timespec* abstime); // 带超时的阻塞等待条件满足，同时释放互斥锁mutex
   
   // 从条件变量cond中唤出一个线程，令其重新获得原先的互斥锁
   // 被唤出的线程此刻将从pthread_cond_wait函数中返回，但如果该线程无法获得原先的锁，则会继续阻塞在加锁上。
   int pthread_cond_signal (pthread_cond_t* cond);
   
   // 从条件变量cond中唤出所有线程
   int pthread_cond_broadcast (pthread_cond_t* cond);
   ```

   pthread_cond_wait用于阻塞等待条件满足，同时释放互斥锁

   pthread_cond_signal用于唤醒pthread_cond_signal阻塞的线程，令其重新获得原先的互斥锁，如果该线程无法获得原先的锁，则会继续阻塞在加锁上。

   **条件变量的一些问题：**

   1. **一个互斥锁可以对应多个条件变量；**

   2. **为什么要引入条件变量？**

      假设存在这样一种情况，多个类似的线程需要等待某一**条件**达成，才能继续任务，**条件**属于临界资源，在访问时需要加锁。假设不存在条件变量，那么解决方案可能是如下这样：

      ```cpp
      while(true)
      {
      	lock();
      	if(条件满足)
      	{
      		doSomething();
      	}
      	unlock();
      }
      ```

      如上所示，在条件未满足之前，会不断的加锁再解锁，这种不断的查询操作是浪费资源的。

      引入条件变量后，若条件不满足，则相应线程被阻塞直至条件发生变化被唤醒，再去查询条件是否满足，避免了上述条件变化发生之前的无用查询包括加解锁。

   3. **为什么条件变量要和互斥锁一起使用？**

      其一，在pthread_cond_wait()前，需要进行条件判断，而此**条件**属于临界资源，需要在访问前加锁，此为保护临界资源的需要。

      其二，这也是面试官关注的，可以把问题转化为：**为什么pthread_cond_wait()需要传入一锁作为参数？**

      当条件不满足时，pthread_cond_wait()内部将执行两个步骤，并保证两个操作的原子性：

      1. **将当前线程加入条件信号的等待队列。**
      2. **作为参数传入的锁，解除对临界资源的锁定。**（方便消费者线程去消费，或者生产者去生产）

   4. 生产者消费者模型还有别的实现方法吗？

      有。除了使用条件变量+互斥锁的方式实现，还可以使用信号量来实现。

      

   ​	**项目中使用了条件变量吗？项目中线程同步机制有体现吗？**

   ​	使用了，**在线程池设计中**，使用了互斥锁保护对http请求的解析和http响应数据准备，保证操作的原子性；**在实现异步日志的时候**，使用生产者消费者模型实现了一个阻塞队列，下面是一个简单的阻塞队列的实现。项目中具体的东西，明天补充补充。

   ```cpp
   #include <iostream>
   #include <stdio.h>
   #include <queue>
   #include <pthread.h>
   using namespace std;
   
   //线程安全的缓冲队列
   #define QUEUE_MAX 5
   class BlockQueue
   {
    public:
       BlockQueue(int maxq = QUEUE_MAX)
           :_capacity(maxq)
       {
           pthread_mutex_init(&_mutex, NULL);
           pthread_cond_init(&_pro_cond, NULL);
           pthread_cond_init(&_cus_cond, NULL);
       }
       ~BlockQueue()
       {
           pthread_mutex_destroy(&_mutex);
           pthread_cond_destroy(&_pro_cond);
           pthread_cond_destroy(&_cus_cond);
       }
       bool push(const int& data)
       {
           //生产者将数据入队，若数据满了需要阻塞
           pthread_mutex_lock(&_mutex);
           while (_queue.size() == _capacity)
           {
               // 将当前线程加入条件信号的等待队列，释放锁 要等待队列不是满的信号唤醒
               pthread_cond_wait(&_pro_cond, &_mutex);
               // 被唤醒之后 重新获得锁
           }
           //将数据入队
           _queue.push(data);
           //解锁
           pthread_mutex_unlock(&_mutex);
           //唤醒消费者线程
           pthread_cond_signal(&_cus_cond);
           return true;
       }
       bool pop(int *data)
       {
           //消费者将数据出队，若没有数据需要阻塞
           pthread_mutex_lock(&_mutex);
           while (_queue.empty())
           {
               // 将当前线程加入条件信号的等待队列，释放锁 要等待队列不是空的信号唤醒
               pthread_cond_wait(&_cus_cond, &_mutex);
               // 被唤醒之后 重新获得锁
           }
           //获取队头元素
           *data = _queue.front();
           //将数据出队
           _queue.pop();
           //解锁
           pthread_mutex_unlock(&_mutex);
           //唤醒生产者线程
           pthread_cond_signal(&_pro_cond);
           return true;
       }
   private:
       queue<int> _queue;//简单队列
       int _capacity;//最大节点数量
       pthread_mutex_t _mutex;//互斥变量
       pthread_cond_t _pro_cond;//生产者条件变量
       pthread_cond_t _cus_cond;//消费者条件变量
   };
   
   void *thr_productor(void* arg )
   {
       BlockQueue *queue = (BlockQueue*)arg;
       int i = 0;
       while (1)
       {
           //生产者生成数据
           queue->push(i);
           printf("productor push data:%d\n", i++);
       }
       return NULL;
   }
   void *thr_customer(void* arg )
   {
       BlockQueue *queue = (BlockQueue*)arg;
       while (1)
       {
           //消费者不断获取数据
           int data;
           queue->pop(&data);
           printf("customer pop data:%d\n", data);
       }
       return NULL;
   }
   
   int main()
   {
       int ret, i;
       pthread_t ptid[4], ctid[4];
       BlockQueue queue;
   
       for (i = 0; i < 4; ++i)
       {
   		ret = pthread_create(&ptid[i], NULL, thr_productor, (void*)&queue);
           if (ret != 0)
           {
               printf("create productor thread error\n");
               return -1;
           }
           ret = pthread_create(&ctid[i], NULL, thr_customer, (void*)&queue);
           if (ret != 0)
           {
               printf("create productor thread error\n");
               return -1;
           }
       }
       for (i = 0; i < 4; i++)
       {
           pthread_join(ptid[i], NULL);
           pthread_join(ctid[i], NULL);
       }
       return 0;
   }
   ```

5. **读写锁**

   顾名思义『读写锁』就是**对于临界区区分读和写**。在读多写少的场景下，不加区分的使用互斥量显然是有点浪费时间以及占用资源。

   读写锁的特性：

   - 当读写锁被加了**写锁**时，其他线程对该锁**加读锁或者写锁都会阻塞**（不是失败）。
   - 当读写锁被加了读锁时，其他线程对该锁**加写锁会阻塞**，**加读锁会成功**。

   因而适用于多读少写的场景。

   实现：

   ```cpp
   // 声明一个读写锁
   pthread_rwlock_t rwlock;
   ...
   // 在读之前加读锁
   pthread_rwlock_rdlock(&rwlock);
   
   ... 共享资源的读操作
   
   // 读完释放锁
   pthread_rwlock_unlock(&rwlock);
   
   // 在写之前加写锁
   pthread_rwlock_wrlock(&rwlock); 
   
   ... 共享资源的写操作
   
   // 写完释放锁
   pthread_rwlock_unlock(&rwlock);
   
   // 销毁读写锁
   pthread_rwlock_destroy(&rwlock);
   ```

   C++11中有互斥量、条件变量但是并没有引入读写锁。而在**C++17**中出现了一种新锁：**std::shared_mutex**。用它可以模拟实现出读写锁，具体如下：

   ```cpp
   #include <iostream>
   #include <thread>
   #include <shared_mutex>
   
   std::shared_mutex mtx; // 创建一个读写锁对象
   int count = 0; // 共享资源
   
   void read() {
       std::shared_lock<std::shared_mutex> lock(mtx); // 创建一个读锁保护对象，自动加读锁
       std::cout << "count = " << count << std::endl; // 读取共享资源
   } // 读锁保护对象被销毁时，自动解读锁
   
   void write() {
       std::unique_lock<std::shared_mutex> lock(mtx); // 创建一个写锁保护对象，自动加写锁
       ++count; // 修改共享资源
   } // 写锁保护对象被销毁时，自动解写锁
   
   int main() {
       std::thread t1(read);
       std::thread t2(read);
       std::thread t3(write);
       t1.join();
       t2.join();
       t3.join();
       return 0;
   }
   ```



#### 3. 悲观锁和乐观锁了解吗？

乐观锁和悲观锁是两种不同的**并发控制策略**。

当一个线程使用数据时，悲观锁总是认为其它线程也会过来修改这个数据。为了保证数据安全，其采用的是一种先加锁再访问的策略，其它线程要想也访问该数据则被阻塞等待、直到其获取到锁才可以访问。

而对于乐观锁而言，其与悲观锁的思想则恰恰相反，其认为**在使用数据的过程中其它线程不会修改这个数据，故不加锁直接访问**。而当该线程需要**提交更新、修改时**，才会判断该数据在此期间有没有被其它线程更新、修改。如果其它线程确实没有修改，则该线程直接写入完成更新；反之如果该数据已经被其它线程更新、修改，则该线程将放弃本次数据的更新提交操作以避免出现冲突，并通过报错、重试等方式进行下一步处理。

**CAS算法**就是乐观锁的一种典型实现。

悲观锁和乐观锁是一种编程的思想，跟互斥锁，自旋锁等具体的锁不是一个级别的概念，悲观锁真的会用到锁，**乐观锁其实根本没有加锁**，而是通过正常的编程方式去判断在本线程读写之间数据是否被修改过。



#### 4. 那详细说一下CAS算法呢？

CAS全名是Compare and swap（**比较与交换算法**），是基于乐观锁的思想实现的一种算法。

- CAS操作包含三个操作数——**内存位置（V）**、**预期原值（A）**、**新值（B）**。
- 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。

一个CAS涉及到以下操作：

假设内存中的原数据V，旧的预期值A，需要修改的新值B

- **比较 A 与 V 是否相等**
- **如果比较相等，将 B 写入 V**
- **返回操作是否成功**

其中的过程：当多个线程同时使用CAS 操作一个变量时，只有一个线程会胜出，并成功更新，其余线程均会失败。但是失败的线程不会挂起，仅是被告知失败，并且允许再次尝试，当然也允许实现的线程放弃操作。基于这样的原理，**CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰。**

简单实现：

```cpp
//输入一个pAddr的地址，在函数内部判断其的值是否与期望值nExpected相等
//如果相等那么就将pAddr的值改为nNew并同时返回true；否则就返回false，什么都不做
 
bool compare_and_swap(int *pAddr, int nExpected, int nNew)
{
    if(*pAddr == nExpected)
    {
        *pAddr = nNew;
        return true;
    }
    else
        return false;
}
```



#### 5. C++11的多线程知识

c++11中使用thread来替代pthread的功能，具有非常多的新特性，下面简单介绍一下。

##### 1. **lock和unlock**

这个就是对应的pthread的pthread_mutex_lock(&mutex)和pthread_mutex_unlock(&mutex)不再多说。

```cpp
void count10000() {
	for (int i = 1; i <= 10000; i++) {
		mtx.lock();
		n++;
		mtx.unlock();
	}
}
int main() {
	thread th[100];
	for (thread &x : th)
		x = thread(count10000);
	for (thread &x : th)
		x.join();
	cout << n << endl;
	return 0;
}
```



##### 2. lock_guard和uniqie_lock

c++11实现互斥锁除了使用上面的方法，还可以使用：

```cpp
mutex mt;
lock_guard<mutex> guard(mt);
```

只需要在临界区之前使用这一句话即可，不需要解锁，这是因为lock_guard使用了RALL的设计思想，将资源和对象的声明周期绑定在一起，离开了作用域之后guard对象就销毁了，此时锁就自动释放，不需要人为解锁。

虽然lock_guard挺好用的，但是有个很大的缺陷，在定义lock_guard的地方会调用构造函数加锁，在离开定义域的话lock_guard就会被销毁，调用析构函数解锁。这就产生了一个问题，如果这个定义域范围很大的话，**那么锁的粒度就很大，很大程序上会影响效率**。

所以为了解决lock_guard锁的粒度过大的原因，unique_lock就出现了。

```cpp
mutex mt;
unique_lock<mutex> unique(mt);
```

使用uniqie_lock可以像lock_guard一样使用析构函数解锁，也可以使用unique.unlock()提前解锁，更加灵活。



##### 3. atomic

原子类型，使用atomic定义的变量是原子变量，原子操作是**最小的并且不可并行化的操作**，这就意味着即使是多线程，也要像同步进行一样**同步操作**atomic对象，从而省去了mutex上锁、解锁的时间消耗。

```cpp
// Compiler: MSVC 19.29.30038.1
// C++ Standard: C++17
#include <iostream>
#include <thread>
// #include <mutex> //这个例子不需要mutex了
#include <atomic>
using namespace std;
atomic_int n = 0;   // atomic<int> n = 0;也是一样的
void count10000() {
	for (int i = 1; i <= 10000; i++) {
		n++;
	}
}
int main() {
	thread th[100];
	for (thread &x : th)
		x = thread(count10000);
	for (thread &x : th)
		x.join();
	cout << n << endl;
	return 0;
}
```



##### 4. async

async是一个函数，可以根据情况选择同步执行或创建新线程来异步执行，当然也可以手动选择。**对于async的返回值操作也比thread更加方便**。

和thread一样，async传递参数的时候是按照左值引用，如果需要传递右值，需要用ref或cref包装。

```cpp
#include <iostream>
#include <thread>
#include <future>
using namespace std;
int main() {
	async(launch::async, [](const char *message){
		cout << message << flush;
	}, "Hello, ");
	cout << "World!" << endl;
	return 0;
}
```



##### 6. condition_variable

wait只能配合unique_lock使用：

```cpp
lock_guard<mutex> locker(_mutex);
cv.wait(_mutex);
```

notify_all()唤醒所有等待的线程，notify_one随机唤醒一个等待的线程。



#### 6. 多线程的实际应用

##### 1. 三个线程交替打印ABC

基于pthread的实现：

```cpp
#include <iostream>
#include <pthread.h>
using namespace std;

pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t condA = PTHREAD_COND_INITIALIZER;
pthread_cond_t condB = PTHREAD_COND_INITIALIZER;
pthread_cond_t condC = PTHREAD_COND_INITIALIZER;
enum state {
    threadA = 0,
    threadB = 1,
    threadC = 2,
};
int flag = threadA;

void *printA(void *arg) {
    for (int i = 0; i < 10; ++i) {
        pthread_mutex_lock(&mutex);
        if (flag != threadA) {
            pthread_cond_wait(&condA, &mutex);
        }
        cout << 'A';
        pthread_mutex_unlock(&mutex);
        pthread_cond_signal(&condB);
        flag = threadB;
    }
    return nullptr;
}

void *printB(void *arg) {
    for (int i = 0; i < 10; ++i) {
        pthread_mutex_lock(&mutex);
        if (flag != threadB) {
            pthread_cond_wait(&condB, &mutex);
        }
        cout << 'B';
        pthread_mutex_unlock(&mutex);
        pthread_cond_signal(&condC);
        flag = threadC;
    }
    return nullptr;
}

void *printC(void *arg) {
    for (int i = 0; i < 10; ++i) {
        pthread_mutex_lock(&mutex);
        if (flag != threadC) {
            pthread_cond_wait(&condC, &mutex);
        }
        cout << 'C' << endl;
        pthread_mutex_unlock(&mutex);
        pthread_cond_signal(&condA);
        flag = threadA;
    }
    return nullptr;
}

int main() {
    pthread_t t1, t2, t3, t4;
    pthread_create(&t1, NULL, &printA, NULL);
    pthread_create(&t2, NULL, &printB, NULL);
    pthread_create(&t3, NULL, &printC, NULL);

    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    pthread_join(t3, NULL);
    return 0;
}
```

创建了三个线程，对应3个条件变量，设置响应的状态即可。

**基于thread的实现：**

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
using namespace std;

mutex g_mutex;
condition_variable cv;
enum state {
	threadA = 0,
	threadB = 1,
	threadC = 2,
};
int flag = threadA;

void printfA() {
	for (int i = 0; i < 10; ++i) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != threadA) {
			cv.wait(lk);
		}
		cout << 'A';
		cv.notify_all();
		flag = threadB;
	}
}

void printfB() {
	for (int i = 0; i < 10; ++i) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != threadB) {
			cv.wait(lk);
		}
		cout << 'B';
		cv.notify_all();
		flag = threadC;
	}
}

void printfC() {
	for (int i = 0; i < 10; ++i) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != threadC) {
			cv.wait(lk);
		}
		cout << 'C' << endl;
		cv.notify_all();
		flag = threadA;
	}
}


int main() {
	thread th2(printfA);
	thread th1(printfB);
	thread th3(printfC);

	th1.join();
	th2.join();
	th3.join();
	return 0;
}
```

condition_variable只能配合unique_lock使用，和pthread不同的是，condition_variable使用notify_all将唤醒所有线程，而pthread可以唤醒等待在具体那个条件变量的线程，更加精确。所以使用thread实现的时候，**需要使用while而不能使用if，避免虚假唤醒**。



##### 2. 三个线程交替打印1-100

```cpp
#include <iostream>
#include <thread>
#include <future>
#include <mutex>
#include <condition_variable>
using namespace std;

mutex g_mutex;
int num = 1;
enum state {
	a = 0,
	b = 1,
	c = 2,
};
int flag = a;
condition_variable cv;

void threadA() {
	while (num <= 100) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != a) {
			cv.wait(lk);
		}
		cout << num << endl;
		cv.notify_all();
		num++;
		flag = b;
	}
}

void threadB() {
	while (num <= 100) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != b) {
			cv.wait(lk);
		}
		cout << num << endl;
		cv.notify_all();
		num++;
		flag = c;
	}
}

void threadC() {
	while (num <= 100) {
		unique_lock<mutex> lk(g_mutex);
		while (flag != c) {
			cv.wait(lk);
		}
		cout << num << endl;
		cv.notify_all();
		num++;
		flag = a;
	}
}

int main() {
	thread t1(threadA);
	thread t2(threadB);
	thread t3(threadC);

	t1.join();
	t2.join();
	t3.join();

	system("pause");
	return 0;
}
```



#### 7. 什么是虚假唤醒？

c++11中条件变量不能唤醒等待某个具体的条件变量的线程，只能使用随机唤醒notify_one()或者notify_all()全部唤醒等待的线程，这其中就会存在虚假唤醒。以最简单的3个线程交替打印ABC为例，如果此时打印C的线程打印完成之后，使用notify_all()就会唤醒另外两个线程，如果使用if判断的话，此时就存在虚假唤醒 ，打印错误的结果。

可以使用**while不断比较flag**，就可以解决虚假唤醒的问题。



#### 8. 线程池中的工作线程是一直等待吗？

线程池中的工作线程是处于一直**阻塞等待**的模式下的。因为在我们创建线程池之初时，我们通过循环调用pthread_create往线程池中创建了8个工作线程，工作线程处理函数接口为pthread_create函数原型中第三个参数函数指针所指向的worker函数（自定义的函数），然后调用线程池类成员函数run（自定义）。



#### 9. 你的线程池工作线程处理完一个任务后的状态是什么？

这里要分**两种**情况考虑

（1） 当处理完任务后如果**请求队列为空时**，则这个线程重新回到**阻塞等待**的状态；

（2） 当处理完任务后如果请求队列不为空时，那么这个线程将处于与**其他线程竞争资源的状态**，谁获得锁谁就获得了处理事件的资格。



#### 10. 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？（如何处高并发的问题）

该项目是基于**IO复用的并发模式**。**需要注意的是，不是一个客户连接就对应一个线程**！当客户连接有事件需要处理的时，epoll会进行事件提醒，而后将对应的任务加入请求队列，等待工作线程竞争执行。**如果速度还是慢，那就只能够增大线程池容量**，或者**考虑集群分布式**的做法。



#### 11. 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

会影响接下来的客户请求，因为线程池内**线程的数量时有限的**，如果客户请求占用线程时间过久的话会影响到处理请求的**效率**，当请求处理过慢时会造成后续接受的请求只能在请求队列中等待被处理，从而影响接下来的客户请求。

**应对策略：**

我们可以为线程处理请求对象设置处理超时时间，当一个线程处理某个请求对象的时间达到了超时时间或者n倍超时时间，就将其手动将其断开连接，处理请求队列上其他的请求。



### 三、并发模型相关（常见的八股）

#### 1. **简单说一下服务器使用的并发模型？**

项目实现了两种并发模型：**reactor模式**和**模拟Proactor模式**。

**Proactor模式**为例的工作流程是：

主线程充当**异步线程**，使用**epoll**负责监听所有socket上的事件；

若有新的请求到来，主线程接收得到得到新的连接socket，然后往**epoll内核事件表中注册该socket上的读写事件**；

如果socket上有读写事件发生，主线程负责从socket上读取数据以及向socket写数据，工作线程仅仅负责处理业务逻辑，本项目就是HTTP协议的解析和响应数据准备。

**reactor模式**的工作流程为：

主线程**只**负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程，将socket可读可写事件放入请求队列，**==读写数据、接受新连接及处理客户请求均在工作线程中完成==。(需要区别读和写事件)**



#### 2. **你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？**了解epoll使用步骤及原理吗？

项目实现的是高并发服务器，**epoll 是一种更加高效的 IO 复用技术**，为了监听大量的文件描述符，使用epoll可以高效地处理。

除了epoll之外，常见地IO复用方式还有select和poll。

他们的区别如下：

- select和poll比较像，他们的所有文件描述符都是在用户态被加入其文件描述符集合的，**每次调用都需要将整个集合拷贝到内核态**；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要**执行一个系统调用**。
- select使用**线性表**描述文件描述符集合，**文件描述符有上限**；poll使用**链表来描述**；epoll底层通过**红黑树**来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
- select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll都需要将整个文件集合拷贝到内核，然后会**采用遍历的方式**，遍历整个文件描述符集合去判断各个文件描述符是否有活动；而epoll不需要遍历，当有活动产生时，会自动**触发epoll回调函数通知epoll文件描述符** ，然后内核将这些就绪的问津描述符放在**ready list中等待epoll_wait调用后被处理**。epoll的最大开销来自每次的系统调用。
- select和poll都只能工作在**相对低效的LT模式下**，而epoll同时支持LT和ET模式。

使用的话：epoll适合于监听的文件描述符数量较多，且单位时间仅部分fd活跃的情况下；**当监测的fd数量较小**，且各个fd都很活跃的情况下，建议使用select和poll。

**epoll 的使用步骤及原理如下：**

1. 调用epoll_create()会在内核中创建一个指示**epoll内核事件表的文件描述符**，该描述符将用作其他epoll系统调用的第一个参数。

    在这个结构体中有 2 个比较重要的数据成员：一个是需要检测的文件描述符的信息 struct_root rbr （**==红黑树==**），还有一个是就绪列表struct list_head rdlist，存放检测到数据发送改变的文件描述符信息 （**==双向链表==**）；

2. 调用epoll_ctl() 用于操作内核事件表监控的文件描述符上的事件：注册、修改、删除；
3. 调用epoll_wait() 可以让内核去检测就绪的事件，并将就绪的事件放到就绪列表中并返回，通过返回的事件数组做进一步的事件处理。

**epoll 的两种工作模式：**LT 模式（水平触发），ET 模式（边缘触发）。

**epoll 如何判断数据已经读取完成：**

epoll ET 模式，才需要关注数据是否读取完毕了。使用select或者epoll的LT模式，不用关注，select/epoll检测到有数据可读去读就OK了。

以下是常用的两种方法：

- 针对TCP，调用recv方法，根据==**recv的返回值**==。如果返回值**==小于我们设定的 recv buff 的大小，那么就认为接收完毕。==**
- TCP、UDP都适用，将 socket 设为 NOBLOCK（非阻塞） 状态，然后 select该 socket可读的时候，使用 read/recv 函数读取数据。**当返回值为 -1，并且 errno 是 EAGAIN 或EWOULDBLOCK 的时候，表示数据读取完毕。**

在项目中我使用的是第二种方式。

**epoll为什么要用红黑树**

epoll要在内核中长久维护一个数据结构来存放文件描述符，并且时常会有插入，查找和删除的操作发生，这对内核的效率会产生不小的影响，**==因此需要一种插入，查找和删除效率都不错的数据结构==**来存放这些文件描述符，那么红黑树当然是不二的人选。

#### 3. **什么是ET（边缘触发）、LT（水平触发）？ET、LT优缺点？**

- LT 模式（水平触发）LT（Level - Triggered）是缺省的工作方式，并且同时支持 **Block** 和 **Nonblock Socket**。 在这种做法中，内核检测到一个文件描述符就绪了，然后应用程序可以对这个就绪的 fd 进行 IO 操作。应用程序可以不立即处理该事件，如果不作任何操作，**内核还是会继续通知**。
- ET 模式（边缘触发） ET（Edge - Triggered）是高速工作方式，只支持 **Nonblock socket**。 在这种模式下，epoll_wait检测到文件描述符有事件发生，则将其通知给应用程序，应用程序必须立即处理该事件。必须要一次性将数据读取完，使用非阻塞I/O，读取到出现**EAGAIN**。但是，如果一直不对这个 fd 进行 IO 操作（从而导致它再次变成未就绪 ），内核不会发送更多的通知（only once）。

ET 模式在很大程度上减少了 **epoll 事件被重复触发的次数，因此效率要比 LT 模式高**。epoll 工作在 ET 模式的时候，必须使用**非阻塞套接口**，以避免由于一个文件描述符的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

此外，我在项目中还将文件描述符设置成了**EPOLLONESHOT**事件。

这个参数的意思是一个 socket只能被一个线程同时处理。即使在ET模式下，也有可能会出现一个线程读取某个socket上的数据后开始处理数据，在处理过程中该socket上又有新数据可读，此时另一个线程被唤醒读取，此时出现两个线程处理同一个socket，两个线程同时处理一个socket，会产生未知错误。基于此，需要将socket设置成EPOLLONESHOT。

但是当该线程处理完之后，需要通过epoll_ctl重置EPOLLONESHOT事件，socket才能被其他线程处理。

**怎么解决怎么解决LT的缺点？**

LT模式下，可写状态的 fd 会一直触发事件，该怎么处理这个问题。

数据量很少时直接 send 数据，数据量很多时每次要写数据时，将 fd 绑定 EPOLLOUT 事件，写完后将 fd 同 EPOLLOUT 从 epoll 中移除。

**为什么ET模式一定要设置非阻塞？**

是这样的，LT是对于每个epoll_wait返回的读事件，每次都是读取一定数量的字节，然后返回，若没读完，等待下一次epoll_wait再读，因此**LT的每次读的时候缓冲区都是非空的**（即可以使用阻塞也可以使用非阻塞）；而ET对于epoll_wait返回的读事件，需要使用while循环把所有字节都读取完毕，也就是读到缓冲区为空为止，这样**最后一次读取一定会导致阻塞**，因此需要把ET的读取设置成非阻塞的。

### 四、HTTP报文解析相关

#### **1. 用了状态机啊，为什么要用状态机？**

在逻辑处理模块中，响应HTTP请求采用主从状态机来完成

传统的控制流程都是按照顺序执行的，状态机能**==处理任意顺序的事件==**，并能提供有意义的响应—即使这些事件发生的顺序和预计的不同。

项目中使用主从状态机的模式进行解析，从状态机（parse_line）负责读取报文的一行，主状态机负责对该行数据进行解析，主状态机内部调用从状态机，从状态机驱动主状态机。每解析一部分都会将整个请求的m_check_state状态改变，状态机也就是根据这个状态来进行不同部分的解析跳转的。

#### **2. 状态机的转移图画一下**

![img](https://img-blog.csdnimg.cn/8490e9ceb6c044e0ae259dd41400fef7.png)

- `parse_request_line(text)`，解析请求行，通过请求行的解析我们可以判断该HTTP请求的类型（GET/POST），而请求行中最重要的部分就是`URL`部分，我们会将这部分保存下来用于后面的生成HTTP响应。
- `parse_headers(text)：`解析请求头部，就是GET和POST中`空行`以上，请求行以下的部分。
- `parse_content(text);`，解析请求数据，对于GET来说这部分是空的，因为这部分内容已经以明文的方式包含在了请求行中的`URL`部分了；**只有POST的这部分是有数据的**，**==项目中的这部分数据为用户名和密码，我们会根据这部分内容做登录和校验==**。

**主状态机**

三种状态，标识解析位置。

CHECK_STATE_REQUESTLINE，解析请求行

CHECK_STATE_HEADER，解析请求头

CHECK_STATE_CONTENT，**==解析消息体，仅用于解析POST请求==**

**从状态机**

三种状态，标识解析一行的读取状态。

LINE_OK，完整读取一行，该条件涉及解析请求行和请求头部

LINE_BAD，报文语法有误

LINE_OPEN，读取的行不完整

**处理结果：**

| NO_REQUEST     | **请求不完整，需要继续读取请求报文数据** |
| -------------- | ---------------------------------------- |
| GET_REQUEST    | 获得了完整的HTTP请求                     |
| BAD_REQUEST    | HTTP请求报文有语法错误                   |
| INTERNAL_ERROR | 服务器内部错误                           |

#### 3. **解析报文整体流程**

process_read作为解析报文的入口函数，通过while循环，将主从状态机进行封装，对报文的每一行进行循环处理。

==**明天自己写**==

#### 4. 状态机的缺点？

状态机的缺点就是**性能比较低**，一般一个状态做一个事情，性能比较差，在追求高性能的场景下一般不用，高性能场景一般使用**流水线设计**



#### 5. Web服务器如何接收客户端发来的HTTP请求报文？

 Web服务器端通过 socket 监听来自用户的请求。远端的很多用户会尝试去connect()这个Web Server上正在listen的这个端口，而监听到的这些连接会排队等待被accept()。由于用户连接请求是随机到达的异步事件，每当监听socket（listenfd）listen到新的客户连接并且放入监听队列，我们都需要告诉我们的Web服务器有连接来了，accept这个连接，并分配一个逻辑单元来处理这个用户请求。而且，我们在处理这个请求的同时，还需要继续监听其他客户的请求并分配其另一逻辑单元来处理。这里，**==服务器通过epoll这种I/O复用技术（还有select和poll）来实现对监听socket（listenfd）和连接socket（客户请求）的同时监听。==**



### 五. 定时器相关

#### **1. 为什么要用定时器？**

==为了定期删除非活跃事件，防止连接资源的浪费。==

`非活跃`，是指浏览器与服务器端建立连接后，长时间不交换数据，一直占用服务器端的文件描述符，导致连接资源的浪费。

`定时事件`，是指固定一段时间之后触发某段代码，由该段代码处理一个事件，如从内核事件表删除事件，并关闭文件描述符，释放连接资源。

#### 2. **说一下定时器的工作原理**

服务器主循环为每一个连接创建一个定时器，并对每个连接进行定时。之前用过使用**升序双链表来将所有的定时器串联起来**，但是当有大量客户请求的时候，基于升序链表的定时器添加定时器的效率偏低。所以我们使用了时间轮来存放定时任务。

这里是补充：######################################

升序链表添加定时器的时间复杂度是O(n)，删除定时器的时间复杂度是O(1)，执行定时任务的时间内复杂度是O(1)

对于时间轮而言，调价一个定时器的时间复杂度是O(1)，删除一个定时器的时间复杂度也是O(1)，**但实际执行一个定时器任务的效率要比O(n)好很多，因为时间轮将所有的定时器散列到了不同的链表上**。项目中我们只实现了一个轮子的时间轮，如果使用多个轮子实现时间轮的话，执行一个定时器的任务的时间复杂度将接近O(1)。

###############################################

将定时任务添加到时间轮之后，利用alarm函数周期性地触发**SIGALARM**信号，信号处理函数并不会直接进行定时任务的处理，信号处理函数的功能就是通过管道通知主循环，主循环在最开始将管道的文件描述符使用epoll加入内河事件表中，并进行监听，如果监听到有定时任务，执行对应的逻辑处理，包括关闭当前超时的套接字等。这里使用了统一事件源头，即将定时事件和IO事件都使用epoll来监听，将所有的事件都统一为IO事件。

**为什么管道写端要非阻塞？**

send是将信息发送给套接字缓冲区，如果缓冲区满了，则会阻塞，这时候会进一步增加信号处理函数的执行时间，为此，将其修改为非阻塞。



#### 3. 用了时间轮啊，详细说说时间轮，以及你项目中是怎么使用的呢？

时间轮（TimingWheel）是一个 **存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）**。TimerTaskList 是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务 TimerTask。

![时间轮.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/267bff380ee14b77a34a2bb27a136f74~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

**基本模型构成**

时间轮中，指针以恒定的速度转动，每转动一步就是下一个槽，每次转动称为一个滴答(tick)。一个滴答的时间称为时间轮的间隔槽si(slot interval)，它实际上就是心搏时间。时间轮中公有N个槽，每转动一周的时间为Nsi。每个槽指向一条定时器链表，每条链表上的定时器具有相同的特征：它们的定时时间相差Nsi的整数倍。时间轮正是利用此关系将定时器散列到不同的链表中。假设现在指针指向槽cs，我们要将添加一个定时时间为ti的定时器，则该定时器将被插入槽ts(timer slot)对应的链表中：

```
ts = (cs + (ti / si) ) % N; 
```

项目中，我们设置了一个最小超时时间TIMESLOT，然后将每一个客户连接的定时任务加到时间轮中，时间轮根据当前cs和TIMESLOT计算出需要将该定时任务需要放置的位置。当时间轮的指针下一次指向存放定时任务的槽的时候，会检查定时器是否超时，如果超时，则执行定时回调函数，回调函数通过管道发送定时超时信号给主循环，主循环执行超时处理逻辑。



### 六. 日志相关

#### 1. **说下你的日志系统的运行机制？**

在项目中，我们使用**==单例模式==**创建日志系统，对服务器运行状态、错误信息和访问数据进行记录，该系统可以实现**按天**分类，**超行**分类功能，可以根据实际情况分别使用**==同步和异步==**写入两种方式。

其中异步写入方式，将**生产者-消费者模型**封装为**阻塞队列**，创建一个写线程，工作线程将要写的内容push进队列，写线程从队列中取出内容，写入日志文件。

> **超行、按天分文件逻辑，具体的实现逻辑**
>
> - 日志写入前会判断当前day是否为创建日志的时间，行数是否超过最大行限制
> - - 若为创建日志时间，写入日志，否则按当前时间创建新log，更新创建时间和行数
>   - 若行数超过最大行限制，在当前日志的末尾加count/max_lines为后缀创建新log

- 日志文件
  - 局部变量的**懒汉模式**获取实例
  - 生成日志文件，并判断同步和异步写入方式
- 同步（直接写）
  - 判断是否分文件
  - 直接格式化输出内容，将信息写入日志文件
- 异步（将内容写入阻塞队列）
  - 判断是否分文件
  - 格式化输出内容，将内容写入阻塞队列，创建一个写线程，从阻塞队列取出内容写入日志文件



#### 2. 为什么要异步？和同步的区别是什么？

同步方式写入日志时会产生比较多的系统调用，若是某条日志信息过大，会阻塞日志系统，造成系统瓶颈。**异步日志**，将所写的日志内容先存入**阻塞队列**，**写线程从阻塞队列中取出内容**，写入日志。可以提高系统的并发性能。



#### 3. （创新点）异步日志系统的改进：生产者消费者模式 => 双缓冲机制

**生产者消费者模式存在的问题：**

一般而言，生产者线程与消费者线程**==共享一个缓冲区==**。

消费者从消息队列每读取一条日志信息就写入文件系统，但是写文件操作是很耗时的。频繁的从消息队列中获取数据，而且每次都要上锁，一定会对生产者的写日志效率产生影响，因为生产者也要对消息队列上锁才能把日志信息插入队列的头部，如果此时消息队列正好被消费者锁住了，这样生产者就会一直等待，很大影响到日志系统整体的吞吐率。

![img](https://img-blog.csdnimg.cn/5dba4187629c4e3bb1247437cd700811.png)

针对上述的问题，在项目中我使用了双缓冲机制进行优化：

双缓冲机制的基本思路是：

准备两块 buffer: 1 和 2;

前端负责往 buffer 1 填数据（也就是日志信息）；

后端负责把 buffer 2 的数据写入文件。

当 buffer 1 写满之后，交换 1 和 2，让后端将 buffer 1 的数据写入文件，而前端则往 buffer 2 填入新的日志信息，如此反复。

![img](https://img-blog.csdnimg.cn/2e47c32ee08a4482947ede98e825314b.png)

**缓冲区如何实现交换：**

直接交换两个缓冲区的地址： 把生产者在写入数据时的指向缓冲区1的指针重新指向缓冲区2， 把消费者读取数据时指向的缓冲区2的指针重新指向缓冲区1，这样就达到了交换缓冲区的目的了。（指针直接交换即可）

**双缓冲区的好处是：**

在大部分的时间中，前台线程和后台线程不会操作同一个缓冲区，这也就意味着前台线程的操作，不需要等待后台线程缓慢的写文件操作（因为不需要锁定临界区）。

通过双缓冲技术，很好地解决了生产者和消费者之间的异步操作和速度不匹配问题，提高了日志系统的整体吞吐率。

**为什么设计成双缓冲而不用更多的缓冲区？**

前端缓冲不足时会自动扩展，但是双缓冲足够应付使用场景，因为日志只记录必要的信息，并不会太多。



### 4. 了解哪些设计模式，项目中用到的设计模式？

常用的设计模式包括：单例模式、工厂模式、装饰模式、策略模式、代理模式、观察者模式等

比较了解的是单例模式，项目中使用使用单例模式创建了**日志系统和数据库连接池**。

- 单例模式：单例对象的类**只能允许一个实例存在**，并提供一个访问它的**全局访问点**，该实例被所有程序模块共享。主要解决一个全局使用的类频繁的创建和销毁的问题，是一种**创建型模式**，提供了一种创建对象的最佳方式。
- 单例模式三要素：
  1. 单例类**只能有一个实例**；
  2. 单例类**必须自己创建自己的唯一实例**；
  3. 单例类**必须给所有其他对象提供这一实例**。
- 单例模式实现的两个步骤：
  1. **私有化**构造函数 ，这样别处的代码就无法通过调用该类的构造函数来实例化该类的对象，只有**通过该类提供的静态方法来得到该类的唯一实例**；
  2. 通过**局部静态变量**，利用其只初始化一次的特点，返回静态对象成员。

- 单例模式的优缺点：

  **优点：**

  1. 单例模式可以保证内存里只有一个实例 ， 减少了内存的开销 。
  2. 可以避免对资源的 多重占用 。 （比如写文件操作）
  3. 单例模式设置全局访问点，可以优化和共享资源的访问。

  **缺点：**

  1. 单例模式一般没有接口，不能继承，扩展困难。 如果要扩展，则**除了修改原来的代码，没有第二种途径**，**==违背开闭原则==**。
  2. 在并发测试中，单例模式 不利于代码调试 。 在调试过程中，如果单例中的代码没有执行完，也不能模拟生成一个新的对象。
  3. 单例模式的功能代码通常写在一个类中， 如果功能设计不合理，则很容易违背单一职责原则。

- 单例设计模式的种类

  1. 懒汉模式：不用的时候不去初始化，只有第一次使用的时候才创建该类的实例；
  2. 饿汉模式：在使用该类的对象之前已经创建好该类的实例。

- ##### 为什么需要单例模式：

  1. 节省资源。一个类只有一个实例，不存在多份实例，节省资源。
  2. 方便控制。在一些操作公共资源的场景时，避免了多个对象引起的复杂操作。

- **手撕单例模式：**

  饿汉模式：

  ```cpp
  class single {
  private:
  	single() {}   // 私有化构造函数
  	~single() {}
  public:
  	// 公共静态方法获取实例
  	static single* getinstance();
  };
  single* single::getinstance() {
      static single obj;
      return &obj;
  }
  ```

   **使用函数内的局部静态对象无需加锁和解锁，因为C++11后编译器可以保证内部静态变量的线程安全性**

  饿汉模式（加锁版本）：

  ```cpp
  class single{
  private:
      static pthread_mutex_t lock;
      single(){
          pthread_mutex_init(&lock, NULL);
      }
      ~single(){}
   
  public:
      static single* getinstance();
   
  };
  pthread_mutex_t single::lock;
  single* single::getinstance(){
      pthread_mutex_lock(&lock);
      static single obj;
      pthread_mutex_unlock(&lock);
      return &obj;
  }
  ```

  饿汉模式：

  ```cpp
  class single{
  private:
      static single* p;
      single(){}
      ~single(){}
  public:
      static single* getinstance();
  };
   
  single* single::p = new single();
  single* single::getinstance(){
      return p;
  }
  ```

  **饿汉模式不需要用锁**，就可以实现线程安全。原因在于，在程序运行时就定义了对象，并对其初始化。之后，不管哪个线程调用成员函数getinstance()，都只是返回一个对象的指针。

### 5. **现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？**

消息队列。



### 七. **数据库登录注册相关**

#### 1. 什么是数据库连接池，为什么要创建连接池？

1. 池是资源的容器，这组资源在服务器启动之初就被完全创建好并初始化，本质上是**对资源的复用**。其实和线程池的核心思想一样，都是池化思想，避免连接和释放数据库带来的消耗。当系统开始处理客户请求的时候，如果它需要相关的资源，可以直接从池中获取，无需动态分配；当服务器处理完一个客户连接后,可以把相关的资源放回池中，无需执行系统调用释放资源。

2. 若系统需要**频繁访问数据库**，则需要频繁创建和断开数据库连接，而**创建数据库连接是一个很耗时的操作，也容易对数据库造成安全隐患**。在程序初始化的时候，集中创建多个数据库连接，并把他们集中管理，供程序使用，可以保证较快的数据库读写速度，更加安全可靠。

3. 使用**单例模式和链表创建数据库连接池**，实现对数据库连接资源的复用。

   连接池的功能主要有：**初始化，获取连接、释放连接，销毁连接池**。

   连接池中的多线程使用**信号量**进行通信，使用**互斥锁**进行同步。

数据库连接的获取与释放通过**RAII机制**封装，避免手动释放。

RAII全称是“Resource Acquisition is Initialization”，直译过来是“资源获取即初始化”。

RAII的核心思想是将**资源或者状态与对象的生命周期绑定**，通过C++的语言机制，实现资源和状态的安全管理。

智能指针是RAII最好的例子具体来说：构造函数的时候初始化获取资源，析构函数释放资源。

#### 2. 